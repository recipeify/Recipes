import requests
from bs4 import BeautifulSoup
from language_tags import tags

from ._schemaorg import (
    SchemaOrg,
    SchemaOrgException
)

from ._utils import get_diet_from_tags, normalize_string

# some sites close their content for 'bots', so user-agent must be supplied


HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.7) Gecko/2009021910 Firefox/3.0.7'
}


class AbstractScraper:
    class Decorators:
        """
        Define decorators for AbstractScraper methods here.
        """
        @staticmethod
        def schema_org_priority(decorated):
            """
            Use SchemaOrg parser with priority (if there's data in it)
            On exception raised - continue by default.
            If there's no data (no schema implemented on the site) - continue by default
            """
            def schema_org_priority_wrapper(self, *args, **kwargs):
                function = getattr(self.schema, decorated.__name__)
                if not function:
                    raise SchemaOrgException(
                        "Function '{}' not found in schema"
                        .format(decorated.__name)
                    )

                if not self.schema.data:
                    return decorated(self, *args, **kwargs)

                try:
                    value = function(*args, **kwargs)
                except SchemaOrgException:
                    return decorated(self, *args, **kwargs)
                return value or decorated(self, *args, **kwargs)

            return schema_org_priority_wrapper

        @staticmethod
        def bcp47_validate(function):
            def bcp47_validate_wrapper(self, *args, **kwargs):
                tag = tags.tag(function(self, *args, **kwargs))
                return str(tag) if tag.valid else None
            return bcp47_validate_wrapper

    def __init__(self, url, body, meta_http_equiv=False):
        if body:  # when testing, we load a file
            page_data = body
        else:
            page_data = requests.get(url, headers=HEADERS).content

        self.meta_http_equiv = meta_http_equiv
        self.soup = BeautifulSoup(page_data, "html.parser")
        self.schema = SchemaOrg(page_data)
        self.url = url
        # if self.schema.data:
        #     print("Class: %s has schema." % (
        #         self.__class__.__name__
        #     ))

    def host(self):
        """ get the host of the url, so we can use the correct scraper """
        raise NotImplementedError("This should be implemented.")

    def id(self):
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def title(self):
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def total_time(self):
        """ total time it takes to preparate the recipe in minutes """
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def yields(self):
        """ The number of servings or items in the recipe """
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def image(self):
        """
        Image of the recipe

        Try to fetch it from og:image if not implemented.
        """
        try:
            image = self.soup.find(
                'meta',
                {'property': 'og:image', 'content': True}
            )
            return image.get('content')
        except AttributeError:  # if image not found
            raise NotImplementedError("This should be implemented.")

    @Decorators.bcp47_validate
    @Decorators.schema_org_priority
    def language(self):
        """
        Human language the recipe is written in.

        May be overridden by individual scrapers.
        """
        candidate_languages = set()
        html = self.soup.find(
            'html',
            {'lang': True}
        )
        candidate_languages.add(html.get('lang'))

        # Deprecated: check for a meta http-equiv header
        # See: https://www.w3.org/International/questions/qa-http-and-lang
        meta_language = self.soup.find(
            'meta',
            {
                'http-equiv': lambda x: x and x.lower() == 'content-language',
                'content': True
            }
        ) if self.meta_http_equiv else None
        if meta_language:
            for language in meta_language.get('content').split(','):
                candidate_languages.add(language)
                break

        # If other langs exist, remove 'en' commonly generated by HTML editors
        if len(candidate_languages) > 1 and 'en' in candidate_languages:
            candidate_languages.remove('en')

        # Return the first candidate language
        for language in candidate_languages:
            return language

    @Decorators.schema_org_priority
    def ingredients(self):
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def instructions(self):
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def ratings(self):
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def number_of_raters(self):
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def suitable_for_diet(self):
        return get_diet_from_tags(self.tags())

    @Decorators.schema_org_priority
    def date_published(self):
        raise NotImplementedError("This should be implemented.")

    def reviews(self):
        raise NotImplementedError("This should be implemented.")

    @Decorators.schema_org_priority
    def tags(self):
        tags_list = self.soup.find(
            'meta',
            {'name': 'keywords'}
        )

        if tags_list is not None and type(tags_list['content']) == str:
            tmp = [x.strip() for x in normalize_string(tags_list['content']).split(',')]
            if 'vegetarian' in self.title().lower():
                tmp = set([x.lower() for x in tmp])
                tmp.add('vegetarian')
                return list(tmp)
            return tmp

        return []

    def links(self):
        invalid_href = ('#', '')
        links_html = self.soup.findAll('a', href=True)

        return [
            link.attrs
            for link in links_html
            if link['href'] not in invalid_href
        ]
